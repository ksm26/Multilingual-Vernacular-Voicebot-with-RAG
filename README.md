# ğŸ’¡ Multilingual-Vernacular-Voicebot-with-RAG

This project is an **open-source conversational AI assistant** designed for **rural & semi-urban India**, where users can ask questions about **government schemes, banking, and agriculture advisory** in their **local languages** (Hindi, Punjabi, Tamil, Bengali, etc.).

The system supports:

- ğŸ™ï¸ **Voice-based queries** in multiple Indic languages
- ğŸ”Š **Speech-to-Text (STT)** with Whisper & AI4Bharat ASR models
- ğŸŒ **Retrieval-Augmented Generation (RAG)** for factual answers
- ğŸŒ **Translation** between Indic â†” English (AI4Bharat IndicTrans2)
- ğŸ—‚ï¸ **Knowledge base** built from multilingual scheme/advisory documents
- ğŸ¤– **LLM-powered responses** (Flan-T5, IndicGPT, etc.)
- ğŸ”ˆ **Text-to-Speech (TTS)** in the userâ€™s own language (Indic-TTS)
- ğŸ§  **Conversational memory** to handle follow-ups naturally

---

## ğŸ“‚ Project Structure
â”œâ”€â”€ ai4bharat_tts.py\
â”œâ”€â”€ audio_asr_router.py\
â”œâ”€â”€ config.yaml\
â”œâ”€â”€ data\
â”‚Â Â  â””â”€â”€ schemes_multilingual.csv\
â”œâ”€â”€ langchain_rag.py\
â”œâ”€â”€ models\
â”‚Â Â  â””â”€â”€ indictrans2-indic-en-1B\
â”œâ”€â”€ README.md\
â”œâ”€â”€ realtime_stt.py\
â”œâ”€â”€ retrieval_with_indiclid.py\
â”œâ”€â”€ tts_outputs\
â”‚Â Â  â”œâ”€â”€ en\
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ tts_24314ac84a404a42a98de6d702fd82bc.wav\
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ tts_95c2930869af4eb8acf90814f7184fd9.wav\
â”‚Â Â  â”‚Â Â  â””â”€â”€ tts_e420035404a9430682354f9cccfe1890.wav\
â”‚Â Â  â”œâ”€â”€ hi\
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ tts_04484fec38e84e44a73541e569bc790e.wav\
â”‚Â Â  â”œâ”€â”€ pa\
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ tts_10f3bbd9439f4780898a0f7eae934adf.wav\
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ tts_6165c68bd38f4d5781dbcbc5db103b9a.wav\
â”œâ”€â”€ validate_and_clean.py\
â””â”€â”€ validation_out\
    â””â”€â”€ validation_report.json\


---
## âš™ï¸ Pipeline Flow

    A[ğŸ“‚ Dataset: schemes_multilingual.csv] --> B[ğŸ§¹ validate_and_clean.py â†’ Cleaned corpus]\
    B --> C[ğŸ™ realtime_stt.py (MicRecorder â†’ Audio capture)]\
    C --> D[ğŸ“ audio_asr_router.py / realtime_stt.py (ASR â†’ Transcript)]\
    D --> E[ğŸŒ realtime_stt.py (Language ID)]\
    E --> F[ğŸŒ langchain_rag.py (IndicTranslator: Vernacular â†’ English)]\
    F --> G[ğŸ“– retrieval_with_indiclid.py / langchain_rag.py (Retriever â†’ Context passages)]\
    G --> H[ğŸ¤– langchain_rag.py (Generator: Flan-T5 â†’ Draft Answer in English)]\
    H --> I[ğŸ”„ langchain_rag.py (IndicTranslator: English â†’ Vernacular)]\
    I --> J[ğŸ—£ langchain_rag.py (IndicTTS â†’ Voice synthesis)]\
    J --> K[ğŸ”Š realtime_stt.py (Audio playback)]\
    K --> L[ğŸ§  langchain_rag.py (Conversational Memory â†’ Follow-ups)]\

---
### ğŸ“‘ Technical Notes
âš¡ **Model Choices**
- **ASR (STT)**: AI4Bharat IndicWav2Vec (Hindi, Punjabi) + Whisper (multilingual fallback).
- **Retriever**: IndicLID embeddings (multilingual coverage of Indic scripts).
- **Generator**: Flan-T5 (open-source, smaller footprint, reliable factuality).
- **Translator**: IndicTrans2 (robust bidirectional translation between Indic â†” English).
- **TTS**: Indic-TTS (natural speech in vernacular).

---

### ğŸ”— Orchestration Flow

1. Audio â†’ Transcript (ASR)
2. Transcript â†’ Language ID â†’ Translation (to English)
3. Retrieval (semantic search with IndicLID + FAISS)
4. Generation (Flan-T5 â†’ English answer)
5. Re-translation (English â†’ vernacular)
6. TTS â†’ Audio reply
7. Memory buffer â†’ follow-up handling

---

### ğŸŒ Language Consistency
- Always normalize reasoning in English to avoid model drift.
- Translate responses back into userâ€™s language with IndicTrans2.

---

### ğŸ›¡ï¸ Anti-Hallucination
- Confidence scoring for ASR + Retriever.
- If score < threshold â†’ Bot replies with â€œMujhe is vishay mein jaankari nahi hai.â€
- Deterministic generation (beam search, no sampling) to reduce randomness.

---

## ğŸ”„ End-to-End Voicebot Pipeline

**1. Dataset Preparation (Corpus Prep)**

- `validate_and_clean.py`â†’ Cleans & validates the multilingual dataset (Govt schemes/advisories), fixes encoding, missing translations, and prepares a clean CSV for indexing.

**2. Speech-to-Text (ASR)**

- `audio_asr_router.py` â†’ Routes between multiple ASR models (`ai4bharat/indicwav2vec-hindi`â†’ Hindi ASR, `manandey/wav2vec2-large-xlsr-punjabi` â†’ Punjabi ASR, `openai/whisper-small` â†’ Multilingual ASR (fallback/general-purpose) ) based on confidence.

- `realtime_stt.py` â†’ Records live microphone input, transcribes using single ASR model or router.

**3. Language Detection**
- `realtime_stt.py` â†’ Uses langdetect (if available) or Unicode heuristics to identify query language.

**4. Translation (Vernacular â†’ English, if needed)**

- `langchain_rag.py (inside IndicTranslator class) â†’ Uses `ai4bharat/indictrans2-indic-en` â†’ Indic â†’ English and 
`ai4bharat/indictrans2-en-indic` â†’ English â†’ Indic.

**5. Retrieval (Semantic Search)**
- `retrieval_with_indiclid.py` â†’ Embeds corpus with **IndicLID** from AI4Bharat)  and retrieves relevant passages.
- `langchain_rag.py` â†’ Integrates retrieval step into RAG pipeline.

**6. Generation (Answer Synthesis in English)**
- `langchain_rag.py` (Generator class) â†’ Uses `google/flan-t5-large` â†’ Factual, deterministic generation via beam search.

**7. Re-Translation (English â†’ Userâ€™s Language)**

- `langchain_rag.py` â†’ Translates generated English response back into the userâ€™s vernacular with `ai4bharat/indictrans2-en-indic` â†’ English â†’ Indic.

**8. Text-to-Speech (Voice Response)**
- `langchain_rag.py` â†’ Converts final vernacular text into speech using IndicTTS.
- `realtime_stt.py` â†’ Plays back audio to the user.

**9. Conversational Memory & Follow-ups**
- `langchain_rag.py` â†’ Maintains short-term session memory (last N turns), rewrites follow-up queries, and ensures contextual continuity.

## ğŸ” In-Depth Script Descriptions

## Script 1: realtime_stt.py

This script provides a **real-time interactive voicebot loop**.  
It records audio from the microphone, runs speech-to-text, detects language, retrieves context via RAG, generates an answer, and plays back a speech response.

### Features
- Live audio capture (mic â†’ numpy array).
- **Configurable ASR modes:**
- - `--mode single` â†’ Uses a single ASR model specified by `--asr_model`.
- - `--mode router` â†’ Uses multiple ASR candidates (`--router_candidates`) and automatically picks the best one based on confidence.
- STT with Whisper / AI4Bharat IndicWav2Vec models.
- Supports single ASR model or ASR router mode.
- Language detection (via langdetect or Unicode heuristics).
- Integrates with `LangchainRAG` for retrieval + generation.
- Plays back responses via Indic TTS.

### Usage
**Single ASR model (Whisper):**
```bash
python realtime_stt.py \
    --csv data/schemes_multilingual.csv \
    --config config.yaml \
    --mode single \
    --asr_model openai/whisper-small 
```
**Router mode (multiple ASR models for Hindi, Punjabi, English):**
```bash
python realtime_stt.py \
    --csv data/schemes_multilingual.csv \
    --config config.yaml \
    --mode router \
    --router_candidates '{"hi":"ai4bharat/indicwav2vec-hindi","pa":"manandey/wav2vec2-large-xlsr-punjabi","en":"openai/whisper-small"}'
```

## Script 2: audio_asr_router.py

This module implements a multilingual ASR (Automatic Speech Recognition) router for handling user speech queries.  
It evaluates candidate ASR models and selects the most suitable one for transcription.

### Features
- Supports multiple Indic + multilingual ASR models (e.g., Hindi, Punjabi, Whisper).
- Confidence scoring for selecting the best model.
- Handles audio resampling automatically.
- Falls back to Hugging Face `pipeline` when direct decoding fails.

### Usage
```bash
python audio_asr_router.py
```

## Script 3: langchain_rag.py

This script orchestrates the **Retrieval-Augmented Generation (RAG)** pipeline for the voicebot.  
It ties together retrieval, translation, generation, re-translation, and TTS.

### Features
- Handles end-to-end query flow: Language detection â†’ Translation â†’ Retrieval â†’ Generation â†’ Re-translation â†’ TTS â†’ Conversational memory.
- Detects query language (English, Hindi, Punjabi, etc.).
- Translates Indic â†” English using AI4Bharat IndicTrans2.
- Retrieves top-k relevant passages via FAISS index (RetrieverWithIndicLID).
- Generates factual answers with Flan-T5 (deterministic beam search).
- Re-translates answer into the userâ€™s vernacular.
- Provides spoken response using IndicTTS.
- Maintains conversational memory for follow-ups.
- Confidence handling: falls back to â€œMujhe is vishay mein jaankari nahi hai.â€ when unsure.

### Usage
```bash
python langchain_rag.py \
    --csv data/schemes_multilingual.csv \
    --config config.yaml \
    --indiclid_ft_model ./models/IndicLID-FTR-v1.bin \
    --generator_model google/flan-t5-large
```


## Script 4: retrieval_with_indiclid.py

This script handles **semantic document retrieval** using IndicLID embeddings.  
It is part of the RAG pipeline that powers the voicebotâ€™s knowledge base.

### Features
- Embeds multilingual documents (English, Hindi, Punjabi, etc.) into a shared semantic space.
- Builds and queries a vector store (FAISS/Chroma).
- Supports semantic similarity search for user queries.
- Outputs top-k relevant passages for downstream LLM response generation.

### Usage
```bash
python retrieval_with_indiclid.py
```


## Script 5: validate_and_clean.py

This script validates and cleans the multilingual dataset (CSV) of schemes and advisory content.  
It checks encoding, language correctness, missing/invalid values, and generates a report.

### Features
- Detects CSV encoding automatically.
- Validates presence and correctness of language fields (English, Hindi, Punjabi, etc.).
- Flags missing IDs, empty rows, or invalid `source_url`s.
- Generates a structured JSON report and CSV with problematic rows.
- Optionally outputs a cleaned UTF-8 CSV with consistent formatting.

### Usage
```bash
python validate_and_clean.py \
    --input data/schemes_multilingual.csv \
    --config config.yaml \
    --output_dir ./validation_out \
    --clean
```


